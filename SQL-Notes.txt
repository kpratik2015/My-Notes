## Normalization

The first normal form rule is that we should have no repeating columns. This makes the system much more straightforward and much more useful to search.

Second normal form says that if we have a composite key every column must depend on
the entire key. Suppose we have a dependency from salesperson to salesperson ID, and from customer to customer ID. So those are not depending on the entire primary key. So to resolve that again we take those dependency values and put them into a separate table.

Third normal form is that we need to have none of these dependencies at all.

Boyce Codd normal form or BCNF is important is if we have multiple overlapping candidate keys
so essentially if we’ve got another surrogate key or another candidate key then we should
be able to apply the same rules using that key.
So if there’s multiple columns which work perfectly well as primary keys, you should
be able to use normalization rules on those even if it isn’t the formal primary key.


## Data Types

Format of date stored in SQL: YYYY-MM-DD

datetime2 follows ISO standards. Midnight is 00 and not 24. 

Convert the data into a data type that suits both the storage and SQL Server:

  SELECT CAST(order_date AS VARCHAR(20))

  SELECT CONVERT(VARCHAR(20), order_date) // This is more functional because an extra parameter can be passed like 101 for US-English date or 103 for British-English date format

  SELECT PARSE('Monday, 6 June 2016' AS DATETIME) // PARSE will only convert from strings into dates or DATETIME or a number. So it is limited in the number of different formats you can convert but actually it would convert a lot more information.

We also have: TRY_CAST, TRY_CONVERT, TRY_PARSE. This is useful when if if there is an error with the conversion process, rather than generating the error, we might actually say “ well, we want to carry on, so we are going to just generate a NULL value.


## Schema

It is an improved way of having a boundary around your objects.

### Object Name Resolution

Actually the object has a four-part name.
It has a name that goes, from the server, the database, the schema, the object name and we should try to use four-part names as much as possible, because if we only use, a one-part name, then it says ok, well I’m going to have to go and have a look and find what the default schema is for that user and then look for objects within that.

So three-part name is defining the database or use the current one, four part names you use the specific server or if we don’t use them the current server.
Ok, so just understand what happens with object name resolution, try to always use two-part names and just be aware of what would happen if you use a three or a four-part name.

### Create, Alter, Drop

CREATE TABLE PetStore.Owner
  OwnerID int IDENTITY(1,1) NOT NULL PRIMARY KEY,
  OwnerName nvarchar(50) NOT NULL,
  HairColor nvarchar(10) NULL;

We have an identity column. Owner ID is an identity column starting with 1 and increasing by 1 every time they create

DROP TABLE PetStore.Owner;

ALTER TABLE PetSotre.Owner 
  ADD PrefferedName nvarchar(30) NULL;


ALTER TABLE PetStore.Owner
  DROP COLUMN PreferredName;


In Alter, we want to retain permission and date on that table.

### Temporary Tables

We create a temporary table by starting its name with a hash. It gets automatically deleted after a session but you might want to explicitly delete it once you're done with the table. This temporary table is stored in tempdb. 

There is another type where you would start it with two hashes.
When you start it with two hashes, you get what’s called a global temporary table.
Similar idea, but now it can be seen by other sessions so it’s globally available and that way, we can pass values between different procedures, different queries as long as they’re running at the same time.
(Typically not a good idea)

### Computed Columns

These are derived from other columns or from functions.
They're often used to provide easier access to data without denormalizing it

Example:

CREATE TABLE PetStore.Pet
(
  PetID int IDENTITY(1,1) PRIMARY KEY,
  PetName nvarchar(30) NOT NULL,
  DateOfBirth date NOT NULL,
  YearOfBirth AS DATEPART(year, DateOfBirth)
);

We use a function of datepart that extracts the year from the date of birth.

I can just call that column that would automatically then run the function and it would give you that information from there.
But it is not storing any data.
All that is stored in the schema of the table is that definition.

If you put PERSISTED after 'DATEPART(year, DateOfBirth)', the value, when you create a record or when you update a record, the value is stored in that table.
But, because we have got a calculation in there, it would be automatically maintained.

Updating the date of birth, it would automatically update the year of birth for your data.
You don't have to do anything to do maintenance of it.
Strictly we are breaking normalization rules, I have got year of birth which has a dependency on the date of birth but you have to be pragmatic sometimes and think well actually yes we are, however it means our queries run much faster.

### More on Tables

nvarchar means it uses unicode which is a character set for international character.

For Composite key, you put Primary key syntax at the end.
E.g.
 PRIMARY KEY (CourierID, CourierCode)

varchar(max) is specified so that the quantity of comments is not limited. The text data type is deprecated and has been replaced by varchar(max).

## Types of Data Integrity

1) Domain integrity: Talking about contents of an individual column. We do this by specifying correct data type.

2) Entity integrity: Talking about a whole row and how it works. Unique by primary key. 

3) Referential integrity: Talking about relationships between tables.

Above are theoretical constructs of integrity.

Null actually means unknown.
Now where it becomes really important is with things like numbers because if we average a column and it contains nulls, the nulls are ignored.
They are not treated as zero.

## Constraints

They're basically rules to follow. E.g. End of review date should be greater than start review date.

Note: Field names are in square brackets (Transact SQL)

ALTER TABLE [SalesLT].[Courier] ADD CONSTRAINT [DF_COURIER_StartDate] DEFAULT (getdate()) FOR [StartDate]
GO

ALTER TABLE [SalesLT].[Courier] WITH NOCHECK ADD CONSTRAINT [CK_Courier_ReviewDate] CHECK (([ReviewDate]>[StartDate]))
GO

ALTER TABLE [SalesLT].[Courier] CHECK CONSTRAINT [CK_Courier_ReviewDate]
GO


NOCHECK means don't check current data.
getdate() puts in today's date if no date is given (NULL)


### Primary and Foreign key constraints 

Candidate keys are the columns that are unique and either of them can be primary keys.

Foreign key constraint: It checks the existance of parent when you create a child. E.g. If an employee makes a sale, that should be valid employee ID
This also helps to decide what to do with children when we delete parent. The children can be set to a default value, or deleted.

So primary keys uniquely identify each row in a table and then a foreign key which looks to make sure that that parent record exists in that other table.

### Cascading Referential Integrity

Our database is almost certainly going to have multiple tables and also it is almost certain that you want to enforce a relationship between those tables the data in one reflects the data in another.
And we can create a join between them. This is a process called referential integrity.

So we have got a sales person, called Fay Burton, here.
Now if I delete this salesperson, we can see that she has got some orders against her SalespersonID. So if we delete Fay Burton, what happens?
Well, if we delete Fay Burton, we want to enforce a rule that says, you can’t delete this record, and that would stop Fay Burton from being deleted. So we still have Fay Burton and we still have her orders. To be able to remove Fay Burton, we would have to go through those orders, change those IDs to someone else, so we don’t lose the data, and we can still then delete Fay Burton
because she has no orders anymore.

The next one to have a look at is CASCADE, in here it’s called cascading referential integrity.
So now what we are going to do is okay. We’ve deleted Fay Burton, and it will automatically delete any orders that are placed against her name. So they automatically get deleted.

We can also set a default salesman ID to be inserted for all the employee orders of employees who left the company and have their records deleted.

### Sequences

This is useful to ensure uniqueness in primary key among different tables that may at some point will be merged.


CREATE SEQUENCE Booking.BookingID AS INT
START WITH 20001
INCREMENT BY 10;

CREATE TABLE Booking.FlightBooking
FlightBookingID INT NOT NULL
PRIMARY KEY CLUSTERED
DEFAULT
(NEXT VALUE FOR Booking.BookingID);


NOTE: Go command is optional

### Referential Integrity & cascading delete

CREATE TALBE dbo.Customer
(
  CustomerID int IDENTITY(1,1) PRIMARY KEY,
  CustomerName nvarchar(50) NOT NULL
);

INSERT dbo.Customer VALUES ('John'),('Jake');


CREATE TABLE dbo.customerOrder 
(
  CustomerOrderID int IDENTITY(10001,1) PRIMARY KEY,
  CustomerID int NOT NULL
    FOREIGN KEY REFERENCES dbo.Customer(CustomerID),
  OrderAmount decimal(18,2) NOT NULL
);


INSERT INTO dbo.CustomerOrder (CustomerID, OrderAmount)
  VALUES (1,12.50), (2,14.70);


DELETE FROM dbo.Customer WHERE CustomerID = 1 /* This won't work since there are orders for that customerid*/

/* If needed, we apply cascading delete */

ALTER TABLE dbo.CustomerOrder
  ADD CONSTRAINT FK_CustomerOrder_Customer
  FOREIGN KEY (CustomerID)
  REFERENCES dbo.Customer(CustomerID)
  ON DELETE CASCADE;


Notes:
1. You specify NOT NULL as part of the ALTER COLUMN argument.
2. You specify PRIMARY KEY as part of the ADD CONSTRAINT argument.
3. To use the default value, you do not specify a value.


## How SQL Server Accesses Data

If there is no index, SQL will do table scan. The system will scan through all of the records in the table and you will see this if you look at the plans that SQL Server uses to answer the questions in a query.

Above method is not optimum which is why we create index.

Let's look at clustered index:
Now the clustered index at the lowest level or the leaf level, it has all of the data. It creates pages of primary key id which reference to actual data on disk. On the top might be a page (Layer 3) containing range of employee ID for each index page.

We might want to have lots of indexes but the downside is that the indexes need to be maintained. The index is brilliant for queries but they would slow down in updates and delete operations for our data. Since on the same transaction of update or delete, the index needs to be updated too.

Let's talk about non-clustered index:
In these ones, the leaf level is only going to have the columns I am interested in indexing.
Let’s say I am interested in indexing the last name.
So I have the last name column and the other value I am going to have in there is the clustering key, the value that’s in the clustered index.
Now what happens now is a slightly different scenario because I am now going to look for a value.
I am going to find what I am looking for it will point to a page, it won’t have all the data but it will have the clustering key.
Once I have got that clustering key, we can then go on to our clustered index and find all of the data.
So we can have one clustered index and as many non-clustered indexes as we require and our non-clustered indexes will have a clustering key that then gives us the information required to then go to the clustered index.

### Selectivity, Density and Index Depth

Through example, selectivity:
So by combining with something else and actually we say ok, distribution center plus date plus customer, that is a composite index, it could be very selective.
So selectivity is very very useful for an index.
Low selectivity something that doesn’t have very many different values or the query we run will very rarely generate anything but a couple of those values is not a very useful index to create on your system.

Density: Nearer to unique something is the more useful is for an index because then less records will get returned

Index Depth: If you've got huge amounts of data in that index, you've very very large composite index.
Then you get less records in each page and because you get less records in each page, you require more pages, more pages means that we have to have more levels in our index and therefore we’ve got more page reads to get the data out the index.
The index is less effective, the index still need to be maintained, so again you can lose some of the benefits without gaining the performance.

### Data Types and Indexes

Numeric data type is the most efficient for index. However, if queries run more on character data type like first name last name or so... It might be better to index that.

### Indexing Computed Columns

So indexing computed columns perfectly allowed.
Just make sure that you are aware of what would happen with the negative side of it if you do updates that later need to be maintained and just be aware that they have to be deterministic, i.e. the results of our query will always be the same, even if I run it next week, next month, next year, the result will always be the same of a deterministic query.

NOTE: We can make composite index. In this case it is best to have first column as highly selective i.e. it will remove 90% of data on search. E.g. (Last Name, First Name)

### Index Statistics

SQL uses this to optimize query before it is run. Like which index will be actually useful and if no index at all will be useful. 

Index statistics: So your indexes hold a statistics and it will have things like the selectivity, the lowest value, highest value, and a histogram of values through there, a sampling of data if you like.
So that SQL can get a good idea of what data it contains and therefore how it should actually optimize that query.

Statistics by default, are auto created and auto updated.
You can automatically update, and there’s a stored procedure called SPUPDATESTATS that will allow you to, ok we’ve got some really important month end reports running now, I’d like to update my statistics prior to that because I know that I need a high performance for those queries.

### Viewing Index Statistics

E.g.:
DBCC SHOW_STATISTICS( "Sales.SalesOrderDetail", PK_SalesOrderDetail_SalesOrderID_SalesOrderDetailID );


