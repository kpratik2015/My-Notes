## Normalization

The first normal form rule is that we should have no repeating columns. This makes the system much more straightforward and much more useful to search.

Second normal form says that if we have a composite key every column must depend on the entire key. Suppose we have a dependency from salesperson to salesperson ID, and from customer to customer ID. So those are not depending on the entire primary key. So to resolve that again we take those dependency values and put them into a separate table.

Third normal form is that we need to have none of these dependencies at all.

Boyce Codd normal form or BCNF is important is if we have multiple overlapping candidate keys
so essentially if we’ve got another surrogate key or another candidate key then we should
be able to apply the same rules using that key.
So if there’s multiple columns which work perfectly well as primary keys, you should
be able to use normalization rules on those even if it isn’t the formal primary key.


## Data Types

Format of date stored in SQL: YYYY-MM-DD

datetime2 follows ISO standards. Midnight is 00 and not 24. 

Convert the data into a data type that suits both the storage and SQL Server:

  SELECT CAST(order_date AS VARCHAR(20))

  SELECT CONVERT(VARCHAR(20), order_date) // This is more functional because an extra parameter can be passed like 101 for US-English date or 103 for British-English date format

  SELECT PARSE('Monday, 6 June 2016' AS DATETIME) // PARSE will only convert from strings into dates or DATETIME or a number. So it is limited in the number of different formats you can convert but actually it would convert a lot more information.

We also have: TRY_CAST, TRY_CONVERT, TRY_PARSE. This is useful when if if there is an error with the conversion process, rather than generating the error, we might actually say “ well, we want to carry on, so we are going to just generate a NULL value.


## Schema

It is an improved way of having a boundary around your objects.

### Object Name Resolution

Actually the object has a four-part name.
It has a name that goes, from the server, the database, the schema, the object name and we should try to use four-part names as much as possible, because if we only use, a one-part name, then it says ok, well I’m going to have to go and have a look and find what the default schema is for that user and then look for objects within that.

So three-part name is defining the database or use the current one, four part names you use the specific server or if we don’t use them the current server.
Ok, so just understand what happens with object name resolution, try to always use two-part names and just be aware of what would happen if you use a three or a four-part name.

### Create, Alter, Drop

CREATE TABLE PetStore.Owner
  OwnerID int IDENTITY(1,1) NOT NULL PRIMARY KEY,
  OwnerName nvarchar(50) NOT NULL,
  HairColor nvarchar(10) NULL;

We have an identity column. Owner ID is an identity column starting with 1 and increasing by 1 every time they create

DROP TABLE PetStore.Owner;

ALTER TABLE PetSotre.Owner 
  ADD PrefferedName nvarchar(30) NULL;


ALTER TABLE PetStore.Owner
  DROP COLUMN PreferredName;


In Alter, we want to retain permission and date on that table.

### Temporary Tables

We create a temporary table by starting its name with a hash. It gets automatically deleted after a session but you might want to explicitly delete it once you're done with the table. This temporary table is stored in tempdb. 

There is another type where you would start it with two hashes.
When you start it with two hashes, you get what’s called a global temporary table.
Similar idea, but now it can be seen by other sessions so it’s globally available and that way, we can pass values between different procedures, different queries as long as they’re running at the same time.
(Typically not a good idea)

### Computed Columns

These are derived from other columns or from functions.
They're often used to provide easier access to data without denormalizing it

Example:

CREATE TABLE PetStore.Pet
(
  PetID int IDENTITY(1,1) PRIMARY KEY,
  PetName nvarchar(30) NOT NULL,
  DateOfBirth date NOT NULL,
  YearOfBirth AS DATEPART(year, DateOfBirth)
);

We use a function of datepart that extracts the year from the date of birth.

I can just call that column that would automatically then run the function and it would give you that information from there.
But it is not storing any data.
All that is stored in the schema of the table is that definition.

If you put PERSISTED after 'DATEPART(year, DateOfBirth)', the value, when you create a record or when you update a record, the value is stored in that table.
But, because we have got a calculation in there, it would be automatically maintained.

Updating the date of birth, it would automatically update the year of birth for your data.
You don't have to do anything to do maintenance of it.
Strictly we are breaking normalization rules, I have got year of birth which has a dependency on the date of birth but you have to be pragmatic sometimes and think well actually yes we are, however it means our queries run much faster.

### More on Tables

nvarchar means it uses unicode which is a character set for international character.

For Composite key, you put Primary key syntax at the end.
E.g.
 PRIMARY KEY (CourierID, CourierCode)

varchar(max) is specified so that the quantity of comments is not limited. The text data type is deprecated and has been replaced by varchar(max).

## Types of Data Integrity

1) Domain integrity: Talking about contents of an individual column. We do this by specifying correct data type.

2) Entity integrity: Talking about a whole row and how it works. Unique by primary key. 

3) Referential integrity: Talking about relationships between tables.

Above are theoretical constructs of integrity.

Null actually means unknown.
Now where it becomes really important is with things like numbers because if we average a column and it contains nulls, the nulls are ignored.
They are not treated as zero.

## Constraints

They're basically rules to follow. E.g. End of review date should be greater than start review date.

Note: Field names are in square brackets (Transact SQL)

ALTER TABLE [SalesLT].[Courier] ADD CONSTRAINT [DF_COURIER_StartDate] DEFAULT (getdate()) FOR [StartDate]
GO

ALTER TABLE [SalesLT].[Courier] WITH NOCHECK ADD CONSTRAINT [CK_Courier_ReviewDate] CHECK (([ReviewDate]>[StartDate]))
GO

ALTER TABLE [SalesLT].[Courier] CHECK CONSTRAINT [CK_Courier_ReviewDate]
GO


NOCHECK means don't check current data.
getdate() puts in today's date if no date is given (NULL)


### Primary and Foreign key constraints 

Candidate keys are the columns that are unique and either of them can be primary keys.

Foreign key constraint: It checks the existance of parent when you create a child. E.g. If an employee makes a sale, that should be valid employee ID
This also helps to decide what to do with children when we delete parent. The children can be set to a default value, or deleted.

So primary keys uniquely identify each row in a table and then a foreign key which looks to make sure that that parent record exists in that other table.

### Cascading Referential Integrity

Our database is almost certainly going to have multiple tables and also it is almost certain that you want to enforce a relationship between those tables the data in one reflects the data in another.
And we can create a join between them. This is a process called referential integrity.

So we have got a sales person, called Fay Burton, here.
Now if I delete this salesperson, we can see that she has got some orders against her SalespersonID. So if we delete Fay Burton, what happens?
Well, if we delete Fay Burton, we want to enforce a rule that says, you can’t delete this record, and that would stop Fay Burton from being deleted. So we still have Fay Burton and we still have her orders. To be able to remove Fay Burton, we would have to go through those orders, change those IDs to someone else, so we don’t lose the data, and we can still then delete Fay Burton
because she has no orders anymore.

The next one to have a look at is CASCADE, in here it’s called cascading referential integrity.
So now what we are going to do is okay. We’ve deleted Fay Burton, and it will automatically delete any orders that are placed against her name. So they automatically get deleted.

We can also set a default salesman ID to be inserted for all the employee orders of employees who left the company and have their records deleted.

### Sequences

This is useful to ensure uniqueness in primary key among different tables that may at some point will be merged.


CREATE SEQUENCE Booking.BookingID AS INT
START WITH 20001
INCREMENT BY 10;

CREATE TABLE Booking.FlightBooking
FlightBookingID INT NOT NULL
PRIMARY KEY CLUSTERED
DEFAULT
(NEXT VALUE FOR Booking.BookingID);


NOTE: Go command is optional

### Referential Integrity & cascading delete

CREATE TALBE dbo.Customer
(
  CustomerID int IDENTITY(1,1) PRIMARY KEY,
  CustomerName nvarchar(50) NOT NULL
);

INSERT dbo.Customer VALUES ('John'),('Jake');


CREATE TABLE dbo.customerOrder 
(
  CustomerOrderID int IDENTITY(10001,1) PRIMARY KEY,
  CustomerID int NOT NULL
    FOREIGN KEY REFERENCES dbo.Customer(CustomerID),
  OrderAmount decimal(18,2) NOT NULL
);


INSERT INTO dbo.CustomerOrder (CustomerID, OrderAmount)
  VALUES (1,12.50), (2,14.70);


DELETE FROM dbo.Customer WHERE CustomerID = 1 /* This won't work since there are orders for that customerid*/

/* If needed, we apply cascading delete */

ALTER TABLE dbo.CustomerOrder
  ADD CONSTRAINT FK_CustomerOrder_Customer
  FOREIGN KEY (CustomerID)
  REFERENCES dbo.Customer(CustomerID)
  ON DELETE CASCADE;


Notes:
1. You specify NOT NULL as part of the ALTER COLUMN argument.
2. You specify PRIMARY KEY as part of the ADD CONSTRAINT argument.
3. To use the default value, you do not specify a value.


## How SQL Server Accesses Data

If there is no index, SQL will do table scan. The system will scan through all of the records in the table and you will see this if you look at the plans that SQL Server uses to answer the questions in a query.

Above method is not optimum which is why we create index.

Let's look at clustered index:
Now the clustered index at the lowest level or the leaf level, it has all of the data. It creates pages of primary key id which reference to actual data on disk. On the top might be a page (Layer 3) containing range of employee ID for each index page.

We might want to have lots of indexes but the downside is that the indexes need to be maintained. The index is brilliant for queries but they would slow down in updates and delete operations for our data. Since on the same transaction of update or delete, the index needs to be updated too.

Let's talk about non-clustered index:
In these ones, the leaf level is only going to have the columns I am interested in indexing.
Let’s say I am interested in indexing the last name.
So I have the last name column and the other value I am going to have in there is the clustering key, the value that’s in the clustered index.
Now what happens now is a slightly different scenario because I am now going to look for a value.
I am going to find what I am looking for it will point to a page, it won’t have all the data but it will have the clustering key.
Once I have got that clustering key, we can then go on to our clustered index and find all of the data.
So we can have one clustered index and as many non-clustered indexes as we require and our non-clustered indexes will have a clustering key that then gives us the information required to then go to the clustered index.

### Selectivity, Density and Index Depth

Through example, selectivity:
So by combining with something else and actually we say ok, distribution center plus date plus customer, that is a composite index, it could be very selective.
So selectivity is very very useful for an index.
Low selectivity something that doesn’t have very many different values or the query we run will very rarely generate anything but a couple of those values is not a very useful index to create on your system.

Density: Nearer to unique something is the more useful is for an index because then less records will get returned

Index Depth: If you've got huge amounts of data in that index, you've very very large composite index.
Then you get less records in each page and because you get less records in each page, you require more pages, more pages means that we have to have more levels in our index and therefore we’ve got more page reads to get the data out the index.
The index is less effective, the index still need to be maintained, so again you can lose some of the benefits without gaining the performance.

### Data Types and Indexes

Numeric data type is the most efficient for index. However, if queries run more on character data type like first name last name or so... It might be better to index that.

### Indexing Computed Columns

So indexing computed columns perfectly allowed.
Just make sure that you are aware of what would happen with the negative side of it if you do updates that later need to be maintained and just be aware that they have to be deterministic, i.e. the results of our query will always be the same, even if I run it next week, next month, next year, the result will always be the same of a deterministic query.

NOTE: We can make composite index. In this case it is best to have first column as highly selective i.e. it will remove 90% of data on search. E.g. (Last Name, First Name)

### Index Statistics

SQL uses this to optimize query before it is run. Like which index will be actually useful and if no index at all will be useful. 

Index statistics: So your indexes hold a statistics and it will have things like the selectivity, the lowest value, highest value, and a histogram of values through there, a sampling of data if you like.
So that SQL can get a good idea of what data it contains and therefore how it should actually optimize that query.

Statistics by default, are auto created and auto updated.
You can automatically update, and there’s a stored procedure called SPUPDATESTATS that will allow you to, ok we’ve got some really important month end reports running now, I’d like to update my statistics prior to that because I know that I need a high performance for those queries.

### Viewing Index Statistics

E.g.:
DBCC SHOW_STATISTICS( "Sales.SalesOrderDetail", PK_SalesOrderDetail_SalesOrderID_SalesOrderDetailID );



## What Is a View?

A view is just a definition of the structure that you are going to output for your query. It does not contain any data in itself. 
So all we can do with a view is combine data from multiple tables, output it in the format that you want.

Essentially what you are doing is you are presenting the results of a query.

We can combine data from multiple different columns, we can do calculations so we do not have to store calculated data in our database.
We could create it in the view so the view at runtime when it outputs the data, then it runs the calculation and then it presents the data as we want.

So a view is stored.
The definition of it is stored in a table called syscomments.
There is a system table that contains our view definition.

So personally, I often create a view for every single table even if they are not required.
Just so that I know in the future if there is any modification in the structure of my data, that as long as I create it to look the same through the view, the client applications will still continue to work and it gives me that safety, if you like in the future.
So views are incredibly useful things, any talk of them slowing down queries you can realistically ignore it.
They don’t really slow down queries to any extent, but they do give you a huge amount of functionality.

### Dynamic Management Views

These return some really useful system information that we can get from the system for SQL Server databases.

SELECT [database_id]
  ,[total_page_count]
  ,[allocated_extent_page_count]
  ,[unallocated_extent_page_count]
FROM [AdventureWorks].[sys].[dm_db_file_space_usage]

Having said that, this may not have all the information I require and in that case we can actually use a CROSS APPLY statement in here to actually get some more information and this is using sys.database_files because we can join the two together.

So they are very very useful to extract system information and you can use it for troubleshooting and use it for system information or documentation about your system.

### Querying Catalog Views and DMVs

SELECT * FROM sys.views

SELECT * FROM sys.tables

SELECT * FROM sys.objects
WHERE type_desc = 'VIEW'

So, to start with, let's have a look at the dm exec connection.

SELECT * FROM sys.dm_exec_connections

SELECT * FROM sys.dm_exec_sessions

SELECT * FROM sys.dm_exec_requests

SELECT * FROM sys.dm_exec_query_stats
ORDER BY max_logical_reads DESC;

A complex query combining output of multplie DMVs:

SELECT TOP(20) qs.max_logicial_reads, st.text
  FROM sys.dm_exec_query_stats AS qs
  CROSS APPLY sys.dm_exec_sql_text(qs.sql_handle) AS st
  ORDER BY qs.max_logical_reads DESC;


### Creating, Dropping and Altering Views

CREATE VIEW Sales.vHighValueSales
AS
SELECT OrderID, OrderDate, CustomerID, OrderValue
FROM Sales.Orders
WHERE OrderValue > 1000

So a CREATE VIEW statement is basically a SELECT statement, now just make sure in there, a standard select statement we have got the OrderID, OrderDate, CustomerID, OrderValue,
everything in there has got a column name.
So if you use any form of calculation or anything like that, that would appear with a NULL column name, ensure that you supply an alias column name for that column and then you have a perfectly acceptable view definition.

Optional arguments:
WITH ENCRYPTION, SCHEMABINDING, VIEW_METADATA

encryption would stop you to actually be able to see the source
of the view, the definition of the view then maybe some security and maybe I want to avoid people knowing my high value sales that are over a thousand.

schema binding would stop any underlying tables from being edited so their structure wouldn’t end up breaking the view

view_metadata is about holding meta data for the view, so do you want to allow queries to actually to find out information about underlying tables.


To drop a view,
DROP VIEW Sales.vHighValueSales


To alter a view,
ALTER VIEW Sales.vHighValueSales
AS
SELECT OrderID, OrderDate, CustomerID, OrderValue
FROM Sales.Orders
WHERE OrderValue > 1000
WITH CHECK OPTION

Almost same as create view however columns changed and with check option to check the values in our database or not.

people enter records into a view, not knowing it’s a view, when they look at it, they don’t see the data because they don’t realize what the view outputting is different to the actuals being stored in the underlying table. WITH CHECK option prevents that, and makes sure that data going in or being altered meets the same rules as data being returned.


### Ownership Chains

An ownership chain is looking at the path you would take to get to the data.

There are two types: Unbroken and broken

Unbroken chain: give rights to the view to people who do not have any rights on the underlying table. So they can open the view, they can’t open the table directly.

Broken chain: I own a view and XYZ owns the underlying table. Now, in that scenario, if I give someone access to the view, they would also have to have access to the data in the underlying table.

Note: we can have a look at sys views and that gives information about views in the database, lists the views in the database.

### Updateable Views

So data can be modified through a view if you follow these rules:

Now the first one, is if you include columns from one table. If the view includes data from multiple tables, then it can’t update both those tables at once. Having said that, you can create triggers on views that would allow the trigger to do the update on both the tables.

The columns directly reference the table columns, so they can’t use aggregations or computations.
They must be direct table information.

The updates comply with the base table constraints
- NULL or NOT NULL
- Primary and foreign keys can be enforced

WITH CHECK option does not prevent data being inserted that does not comply with the view definition. So if the view only displays data for this year, then you can only enter data for this year, even if the underlying table has data from multiple years.


### Create, alter and drop view

SELECT C.CustomerID, P.FirstName, P.LastName, O.OrderDate, O.SubTotal, O.TotalDue
  FROM Sales.Customer AS C
    INNER JOIN Person.Person as P
      ON C.PersonID=P.BusinessEntityID
    INNER JOIN Sales.SalesOrderHeader as O
      ON C.CustomerID=O.CustomerID


Above query is normal select query. Now we js add create view

CREATE VIEW Sales.vw_CustomerOrders
AS
SELECT C.CustomerID, P.FirstName, P.LastName, O.OrderDate, O.SubTotal, O.TotalDue
  FROM Sales.Customer AS C
    INNER JOIN Person.Person as P
      ON C.PersonID=P.BusinessEntityID
    INNER JOIN Sales.SalesOrderHeader as O
      ON C.CustomerID=O.CustomerID


Now we can query from that view.

SELECT * FROM Sales.vw_CustomerOrders

You'll see that you get exactly the same results so we don't have to put in all the JOIN syntax. We could just select star from the view and it makes it much more straightforward and much more straightforward for applications to see the data that they require because if you've already sorted by columns already done the joins we need. And everything has been created in the structure that we require it.


SELECT OBJECT_DEFINITION(OBJECT_ID(N'Sales.vw_CustomerOrders', N'V'))

VIEW has another criteria which is optional which I'm entering V. That's an object type.
V is VIEW. We could do some other things with that as well. We could use P for STORED PROCEDURE, D for DEFAULT, for example.

We'll run this one, and this returns the OBJECT DEFINITION of that view.

